{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from statistics import mean\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "from sklearn.preprocessing import PowerTransformer\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.utils import resample\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report,ConfusionMatrixDisplay, \\\n",
    "                            precision_score, recall_score, f1_score, roc_auc_score,roc_curve,confusion_matrix\n",
    "\n",
    "\n",
    "from sklearn import metrics \n",
    "from sklearn.model_selection import  train_test_split, RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler,RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r'aps_failure_training_set1.csv',na_values=\"na\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ab_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neg</td>\n",
       "      <td>119358</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>729802.0</td>\n",
       "      <td>332758.0</td>\n",
       "      <td>735544.0</td>\n",
       "      <td>933684.0</td>\n",
       "      <td>970802.0</td>\n",
       "      <td>819800.0</td>\n",
       "      <td>603068.0</td>\n",
       "      <td>44368.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neg</td>\n",
       "      <td>1332</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.800000e+01</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2250.0</td>\n",
       "      <td>846.0</td>\n",
       "      <td>5126.0</td>\n",
       "      <td>52226.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>neg</td>\n",
       "      <td>28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>618.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>neg</td>\n",
       "      <td>680</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3654.0</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>2596.0</td>\n",
       "      <td>2352.0</td>\n",
       "      <td>5542.0</td>\n",
       "      <td>10738.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>neg</td>\n",
       "      <td>2060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7774.0</td>\n",
       "      <td>3158.0</td>\n",
       "      <td>10076.0</td>\n",
       "      <td>73650.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>neg</td>\n",
       "      <td>153002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.640000e+02</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>998500.0</td>\n",
       "      <td>566884.0</td>\n",
       "      <td>1290398.0</td>\n",
       "      <td>1218244.0</td>\n",
       "      <td>1019768.0</td>\n",
       "      <td>717762.0</td>\n",
       "      <td>898642.0</td>\n",
       "      <td>28588.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>neg</td>\n",
       "      <td>2286</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130707e+09</td>\n",
       "      <td>224.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10578.0</td>\n",
       "      <td>6760.0</td>\n",
       "      <td>21126.0</td>\n",
       "      <td>68424.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>neg</td>\n",
       "      <td>112</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>792.0</td>\n",
       "      <td>386.0</td>\n",
       "      <td>452.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>146.0</td>\n",
       "      <td>2622.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>neg</td>\n",
       "      <td>80292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.130706e+09</td>\n",
       "      <td>494.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>699352.0</td>\n",
       "      <td>222654.0</td>\n",
       "      <td>347378.0</td>\n",
       "      <td>225724.0</td>\n",
       "      <td>194440.0</td>\n",
       "      <td>165070.0</td>\n",
       "      <td>802280.0</td>\n",
       "      <td>388422.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>neg</td>\n",
       "      <td>40222</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.980000e+02</td>\n",
       "      <td>628.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>440066.0</td>\n",
       "      <td>183200.0</td>\n",
       "      <td>344546.0</td>\n",
       "      <td>254068.0</td>\n",
       "      <td>225148.0</td>\n",
       "      <td>158304.0</td>\n",
       "      <td>170384.0</td>\n",
       "      <td>158.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9047 rows Ã— 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class  aa_000  ab_000        ac_000  ad_000  ae_000  af_000  ag_000  \\\n",
       "0      neg  119358     NaN  0.000000e+00     NaN     0.0     0.0     0.0   \n",
       "1      neg    1332     NaN  3.800000e+01    34.0     0.0     0.0     0.0   \n",
       "2      neg      28     NaN  0.000000e+00     NaN     0.0     0.0     0.0   \n",
       "3      neg     680     4.0  2.130706e+09    68.0     0.0     0.0     0.0   \n",
       "4      neg    2060     NaN  0.000000e+00     NaN     0.0     0.0     0.0   \n",
       "...    ...     ...     ...           ...     ...     ...     ...     ...   \n",
       "9042   neg  153002     NaN  6.640000e+02   186.0     0.0     0.0     0.0   \n",
       "9043   neg    2286     NaN  2.130707e+09   224.0     0.0     0.0     0.0   \n",
       "9044   neg     112     0.0  2.130706e+09    18.0     0.0     0.0     0.0   \n",
       "9045   neg   80292     NaN  2.130706e+09   494.0     0.0     0.0     0.0   \n",
       "9046   neg   40222     NaN  6.980000e+02   628.0     0.0     0.0     0.0   \n",
       "\n",
       "      ag_001  ag_002  ...    ee_002    ee_003     ee_004     ee_005  \\\n",
       "0        0.0     0.0  ...  729802.0  332758.0   735544.0   933684.0   \n",
       "1        0.0     0.0  ...    2250.0     846.0     5126.0    52226.0   \n",
       "2        0.0     0.0  ...     618.0      56.0       60.0        0.0   \n",
       "3        0.0     0.0  ...    3654.0    1260.0     2596.0     2352.0   \n",
       "4        0.0     0.0  ...    7774.0    3158.0    10076.0    73650.0   \n",
       "...      ...     ...  ...       ...       ...        ...        ...   \n",
       "9042     0.0     0.0  ...  998500.0  566884.0  1290398.0  1218244.0   \n",
       "9043     0.0     0.0  ...   10578.0    6760.0    21126.0    68424.0   \n",
       "9044     0.0     0.0  ...     792.0     386.0      452.0      144.0   \n",
       "9045     0.0     0.0  ...  699352.0  222654.0   347378.0   225724.0   \n",
       "9046     0.0     0.0  ...  440066.0  183200.0   344546.0   254068.0   \n",
       "\n",
       "         ee_006    ee_007    ee_008    ee_009  ef_000  eg_000  \n",
       "0      970802.0  819800.0  603068.0   44368.0     0.0     0.0  \n",
       "1          16.0       0.0       0.0       0.0     0.0     0.0  \n",
       "2           0.0       0.0       0.0       0.0     0.0     0.0  \n",
       "3        5542.0   10738.0      54.0       0.0     0.0     0.0  \n",
       "4         242.0      12.0       0.0       0.0     0.0     0.0  \n",
       "...         ...       ...       ...       ...     ...     ...  \n",
       "9042  1019768.0  717762.0  898642.0   28588.0     0.0     0.0  \n",
       "9043      136.0       0.0       0.0       0.0     0.0     0.0  \n",
       "9044      146.0    2622.0       0.0       0.0     0.0     0.0  \n",
       "9045   194440.0  165070.0  802280.0  388422.0     0.0     0.0  \n",
       "9046   225148.0  158304.0  170384.0     158.0     0.0     0.0  \n",
       "\n",
       "[9047 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047, 171)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "neg    8913\n",
       "pos     134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we are categorizing data in tabular forms and differentiating it in class and numerical features\n",
    "\n",
    "numeric_features = [feature for feature in df.columns if df[feature].dtype != 'O']\n",
    "categorical_features = [feature for feature in df.columns if df[feature].dtype == 'O']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 170 numerical features : ['aa_000', 'ab_000', 'ac_000', 'ad_000', 'ae_000', 'af_000', 'ag_000', 'ag_001', 'ag_002', 'ag_003', 'ag_004', 'ag_005', 'ag_006', 'ag_007', 'ag_008', 'ag_009', 'ah_000', 'ai_000', 'aj_000', 'ak_000', 'al_000', 'am_0', 'an_000', 'ao_000', 'ap_000', 'aq_000', 'ar_000', 'as_000', 'at_000', 'au_000', 'av_000', 'ax_000', 'ay_000', 'ay_001', 'ay_002', 'ay_003', 'ay_004', 'ay_005', 'ay_006', 'ay_007', 'ay_008', 'ay_009', 'az_000', 'az_001', 'az_002', 'az_003', 'az_004', 'az_005', 'az_006', 'az_007', 'az_008', 'az_009', 'ba_000', 'ba_001', 'ba_002', 'ba_003', 'ba_004', 'ba_005', 'ba_006', 'ba_007', 'ba_008', 'ba_009', 'bb_000', 'bc_000', 'bd_000', 'be_000', 'bf_000', 'bg_000', 'bh_000', 'bi_000', 'bj_000', 'bk_000', 'bl_000', 'bm_000', 'bn_000', 'bo_000', 'bp_000', 'bq_000', 'br_000', 'bs_000', 'bt_000', 'bu_000', 'bv_000', 'bx_000', 'by_000', 'bz_000', 'ca_000', 'cb_000', 'cc_000', 'cd_000', 'ce_000', 'cf_000', 'cg_000', 'ch_000', 'ci_000', 'cj_000', 'ck_000', 'cl_000', 'cm_000', 'cn_000', 'cn_001', 'cn_002', 'cn_003', 'cn_004', 'cn_005', 'cn_006', 'cn_007', 'cn_008', 'cn_009', 'co_000', 'cp_000', 'cq_000', 'cr_000', 'cs_000', 'cs_001', 'cs_002', 'cs_003', 'cs_004', 'cs_005', 'cs_006', 'cs_007', 'cs_008', 'cs_009', 'ct_000', 'cu_000', 'cv_000', 'cx_000', 'cy_000', 'cz_000', 'da_000', 'db_000', 'dc_000', 'dd_000', 'de_000', 'df_000', 'dg_000', 'dh_000', 'di_000', 'dj_000', 'dk_000', 'dl_000', 'dm_000', 'dn_000', 'do_000', 'dp_000', 'dq_000', 'dr_000', 'ds_000', 'dt_000', 'du_000', 'dv_000', 'dx_000', 'dy_000', 'dz_000', 'ea_000', 'eb_000', 'ec_00', 'ed_000', 'ee_000', 'ee_001', 'ee_002', 'ee_003', 'ee_004', 'ee_005', 'ee_006', 'ee_007', 'ee_008', 'ee_009', 'ef_000', 'eg_000']\n",
      "\n",
      "We have 1 categorical features : ['class']\n"
     ]
    }
   ],
   "source": [
    "print('We have {} numerical features : {}'.format(len(numeric_features), numeric_features))\n",
    "print('\\nWe have {} categorical features : {}'.format(len(categorical_features), categorical_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#checking missing values\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,5))\n",
    "\n",
    "missing = df.isna().sum().div(df.shape[0]).mul(100).to_frame().sort_values(by=0, ascending = False)\n",
    "\n",
    "ax.bar(missing.index, missing.values.T[0])\n",
    "plt.xticks([])\n",
    "plt.ylabel(\"Percentage missing\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>br_000</th>\n",
       "      <td>82.712501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bq_000</th>\n",
       "      <td>81.739803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp_000</th>\n",
       "      <td>80.081795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bo_000</th>\n",
       "      <td>77.849011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ab_000</th>\n",
       "      <td>76.345750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cr_000</th>\n",
       "      <td>76.345750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bn_000</th>\n",
       "      <td>74.101912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0\n",
       "br_000  82.712501\n",
       "bq_000  81.739803\n",
       "bp_000  80.081795\n",
       "bo_000  77.849011\n",
       "ab_000  76.345750\n",
       "cr_000  76.345750\n",
       "bn_000  74.101912"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop columns containg more than 70% missing values\n",
    "\n",
    "dropcols = missing[missing[0]>70]\n",
    "dropcols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(list(dropcols.index),axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9047, 164)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now check shape of the data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of total missing cells in the data 5.201562571611126%\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df.isnull().sum()\n",
    "total_cells = np.product(df.shape)\n",
    "total_missing = missing_values_count.sum()\n",
    "\n",
    "#Now check the percentage of the missing data\n",
    "\n",
    "print(f\"Percentage of total missing cells in the data {(total_missing/total_cells) * 100}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive: 134, Negative: 8913\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#here we are visualizing unique values and differentiating neg and pos\n",
    "\n",
    "pos = df[df['class']=='pos'].shape[0]\n",
    "neg = df[df['class']=='neg'].shape[0]\n",
    "print(\"Positive: \" + str(pos) + \", Negative: \" +str(neg))\n",
    "sns.catplot(data=df, x=\"class\", kind= \"count\", palette = \"winter_r\", alpha=.6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_clf(true, predicted):\n",
    "    '''This function is used in returning Accuracy , F1-score,Precision,Recall ,Roc-auc Score \n",
    "    using true values and predicted values'''\n",
    "    acc = accuracy_score(true, predicted)\n",
    "    f1 = f1_score(true, predicted)\n",
    "    precision = precision_score(true, predicted)\n",
    "    recall = recall_score(true,predicted)\n",
    "    roc_auc = roc_auc_score(true, predicted)\n",
    "    return acc,f1,precision,recall,roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_cost(y_true,y_pred):\n",
    "    ''' \n",
    "    This function takes y_ture, y_predicted and prints total cost due to missclassification\n",
    "    '''\n",
    "    tn,fp,fn,tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    cost = 10*fp+500*fn\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(X,y,models):\n",
    "    '''This function takes in X and y and models\n",
    "    dictionary as input . Its splits the data into Train\n",
    "    test split . Iterates through the given model dictionary and evalutes the metrics\n",
    "    Returns: Dataframe which contains report of all models metrics with cost'''\n",
    "    X_train , X_test , y_train , y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "    \n",
    "    cost_list = []\n",
    "    models_list = []\n",
    "    accuracy_list = []\n",
    "    \n",
    "    for i in range(len(list(models))):\n",
    "        model = list(models.values())[i]\n",
    "        model.fit(X_train, y_train) #Train model\n",
    "        \n",
    "        #Make predictions\n",
    "        \n",
    "        y_train_pred = model.predict(X_train)\n",
    "        \n",
    "        y_test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Training Set performance\n",
    "        model_train_accuracy,model_train_f1,model_train_precision,\\\n",
    "        model_test_recall,model_train_rocauc_score=evaluate_clf(y_test,y_test_pred)\n",
    "        train_cost = total_cost(y_test, y_test_pred)\n",
    "        \n",
    "        #Testing set performance\n",
    "        model_test_accuracy, model_test_f1, model_test_precision,\\\n",
    "        model_test_recall,model_test_rocauc_score=evaluate_clf(y_train , y_train_pred)\n",
    "        test_cost=total_cost(y_train,y_train_pred)\n",
    "        \n",
    "        print(list(models.keys())[i])\n",
    "        models_list.append(list(models.keys())[i])\n",
    "        \n",
    "        print('Model performance for Training set')\n",
    "        print(\"- Accuracy: {:.4f}\".format(model_train_accuracy))\n",
    "        print(\"- F1 score: {:.4f}\".format(model_train_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_train_precision))\n",
    "        print('- Recall: {:.4f}'.format(model_train_rocauc_score))\n",
    "        print(f'-COST: {train_cost}.')\n",
    "        \n",
    "        print('--------------------')\n",
    "        \n",
    "        print('Model performance for Test set')\n",
    "        print('-Accuracy: {:.4f}'.format(model_test_accuracy))\n",
    "        print('-F1 score : {:.4f}'.format(model_test_f1))\n",
    "        print('- Precision: {:.4f}'.format(model_test_precision))\n",
    "        print('-Recall: {:.4f}'.format(model_test_recall))\n",
    "        print('- ROC Auc Score : {:.4f}'.format(model_test_rocauc_score))\n",
    "        cost_list.append(test_cost)\n",
    "        print('='*35)\n",
    "        print('\\n')\n",
    "    report = pd.DataFrame(list(zip(models_list, cost_list)), columns=['Model Name ', 'Cost']).sort_values(by=[\"Cost\"])\n",
    "    return report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting x and y for all Experiments\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.replace({'pos':1,'neg':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "robustscaler = RobustScaler()\n",
    "X1 = robustscaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_neighbors= 1 || accuracy (0.6944)\n",
      "n_neighbors= 3 || accuracy (0.7086)\n",
      "n_neighbors= 5 || accuracy (0.7101)\n",
      "n_neighbors= 7 || accuracy (0.7008)\n",
      "n_neighbors= 9 || accuracy (0.6812)\n"
     ]
    }
   ],
   "source": [
    "results=[]\n",
    "# define imputer\n",
    "imputer = KNNImputer(n_neighbors=5, weights='uniform', metric='nan_euclidean')\n",
    "strategies = [str(i) for i in [1,3,5,7,9]]\n",
    "for s in strategies:\n",
    "    pipeline = Pipeline(steps=[('i', KNNImputer(n_neighbors=int(s))), ('m', LogisticRegression())])\n",
    "    scores = cross_val_score(pipeline, X1, y, scoring='accuracy', cv=2, n_jobs=-1)\n",
    "    results.append(scores)\n",
    "    print('n_neighbors= %s || accuracy (%.4f)' % (s , mean(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "#combine KNN imputer with selected k-value\n",
    "knn_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',KNNImputer(n_neighbors=3)),\n",
    "        ('RobustScaler', RobustScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_knn = knn_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "#Resampling these minority class can help in creating strategy that can be changed as required\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit this model in order to generate the data\n",
    "X_res, y_res = smt.fit_resample(x_knn,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary which contains models for experiment\n",
    "models = {\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "     \"K-Neighbors Classifier\": KNeighborsClassifier(),\n",
    "    \"XGBClassifier\": XGBClassifier(), \n",
    "     \"CatBoosting Classifier\": CatBoostClassifier(verbose=False),\n",
    "    \"AdaBoost Classifier\": AdaBoostClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9921\n",
      "- F1 score: 0.9922\n",
      "- Precision: 0.9882\n",
      "- Recall: 0.9921\n",
      "-COST: 14340.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9857\n",
      "- F1 score: 0.9858\n",
      "- Precision: 0.9818\n",
      "- Recall: 0.9856\n",
      "-COST: 36800.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9819\n",
      "- F1 score: 0.9821\n",
      "- Precision: 0.9790\n",
      "- Recall: 0.9819\n",
      "-COST: 53990.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9838\n",
      "-F1 score : 0.9838\n",
      "- Precision: 0.9814\n",
      "-Recall: 0.9862\n",
      "- ROC Auc Score : 0.9838\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.5855\n",
      "- F1 score: 0.6924\n",
      "- Precision: 0.5529\n",
      "- Recall: 0.5828\n",
      "-COST: 314420.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.5828\n",
      "-F1 score : 0.6889\n",
      "- Precision: 0.5486\n",
      "-Recall: 0.9254\n",
      "- ROC Auc Score : 0.5835\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9729\n",
      "- F1 score: 0.9735\n",
      "- Precision: 0.9606\n",
      "- Recall: 0.9728\n",
      "-COST: 49860.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9796\n",
      "-F1 score : 0.9798\n",
      "- Precision: 0.9689\n",
      "-Recall: 0.9910\n",
      "- ROC Auc Score : 0.9797\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9962\n",
      "- F1 score: 0.9963\n",
      "- Precision: 0.9938\n",
      "- Recall: 0.9962\n",
      "-COST: 4940.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9953\n",
      "- F1 score: 0.9953\n",
      "- Precision: 0.9928\n",
      "- Recall: 0.9953\n",
      "-COST: 8010.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9993\n",
      "-F1 score : 0.9993\n",
      "- Precision: 0.9992\n",
      "-Recall: 0.9994\n",
      "- ROC Auc Score : 0.9993\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9686\n",
      "- F1 score: 0.9690\n",
      "- Precision: 0.9643\n",
      "- Recall: 0.9685\n",
      "-COST: 95550.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9685\n",
      "-F1 score : 0.9686\n",
      "- Precision: 0.9644\n",
      "-Recall: 0.9729\n",
      "- ROC Auc Score : 0.9686\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report_knn = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>8720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>134410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>198730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>389070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1257200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name      Cost\n",
       "0           Random Forest        0\n",
       "1           Decision Tree        0\n",
       "5           XGBClassifier       10\n",
       "6  CatBoosting Classifier     8720\n",
       "4  K-Neighbors Classifier   134410\n",
       "2       Gradient Boosting   198730\n",
       "7     AdaBoost Classifier   389070\n",
       "3     Logistic Regression  1257200"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X.select_dtypes(exclude=\"object\").columns\n",
    "\n",
    "#Fitting this simple imputer with strategy median\n",
    "median_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('imputer',SimpleImputer(strategy='median')),\n",
    "        ('RobustScaler',RobustScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit X with median_pipeline\n",
    "X_median = median_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling this minority class . the strategy can be changed as per requirements\n",
    "smt = SMOTETomek(random_state = 42, sampling_strategy='minority')\n",
    "#Fit the model to generate the data\n",
    "X_res, y_res = smt.fit_resample(X_median, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9914\n",
      "- F1 score: 0.9915\n",
      "- Precision: 0.9863\n",
      "- Recall: 0.9913\n",
      "-COST: 12480.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9862\n",
      "- F1 score: 0.9864\n",
      "- Precision: 0.9804\n",
      "- Recall: 0.9862\n",
      "-COST: 27900.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9810\n",
      "- F1 score: 0.9812\n",
      "- Precision: 0.9757\n",
      "- Recall: 0.9809\n",
      "-COST: 48240.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9840\n",
      "-F1 score : 0.9840\n",
      "- Precision: 0.9813\n",
      "-Recall: 0.9867\n",
      "- ROC Auc Score : 0.9840\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.6287\n",
      "- F1 score: 0.7162\n",
      "- Precision: 0.5828\n",
      "- Recall: 0.6260\n",
      "-COST: 298030.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.6326\n",
      "-F1 score : 0.7167\n",
      "- Precision: 0.5824\n",
      "-Recall: 0.9317\n",
      "- ROC Auc Score : 0.6332\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9718\n",
      "- F1 score: 0.9724\n",
      "- Precision: 0.9596\n",
      "- Recall: 0.9716\n",
      "-COST: 54430.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9789\n",
      "-F1 score : 0.9791\n",
      "- Precision: 0.9683\n",
      "-Recall: 0.9902\n",
      "- ROC Auc Score : 0.9789\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9949\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9916\n",
      "- Recall: 0.9949\n",
      "-COST: 6100.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9935\n",
      "- F1 score: 0.9936\n",
      "- Precision: 0.9889\n",
      "- Recall: 0.9935\n",
      "-COST: 6790.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9996\n",
      "-F1 score : 0.9996\n",
      "- Precision: 0.9997\n",
      "-Recall: 0.9996\n",
      "- ROC Auc Score : 0.9996\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9695\n",
      "- F1 score: 0.9699\n",
      "- Precision: 0.9645\n",
      "- Recall: 0.9694\n",
      "-COST: 89540.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9696\n",
      "-F1 score : 0.9696\n",
      "- Precision: 0.9656\n",
      "-Recall: 0.9737\n",
      "- ROC Auc Score : 0.9696\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Now Train these models\n",
    "report_median = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>146570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>190760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>377710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1142410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name      Cost\n",
       "0           Random Forest        0\n",
       "1           Decision Tree        0\n",
       "5           XGBClassifier      500\n",
       "6  CatBoosting Classifier     5590\n",
       "4  K-Neighbors Classifier   146570\n",
       "2       Gradient Boosting   190760\n",
       "7     AdaBoost Classifier   377710\n",
       "3     Logistic Regression  1142410"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import miceforest as mf\n",
    "\n",
    "X_mice = X.copy()\n",
    "kernel = mf.ImputationKernel(\n",
    "    X_mice,\n",
    "    random_state = 1989\n",
    ")#Run the MICE Algorithm for 3 iterations kernel.mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa_000</th>\n",
       "      <th>ac_000</th>\n",
       "      <th>ad_000</th>\n",
       "      <th>ae_000</th>\n",
       "      <th>af_000</th>\n",
       "      <th>ag_000</th>\n",
       "      <th>ag_001</th>\n",
       "      <th>ag_002</th>\n",
       "      <th>ag_003</th>\n",
       "      <th>ag_004</th>\n",
       "      <th>...</th>\n",
       "      <th>ee_002</th>\n",
       "      <th>ee_003</th>\n",
       "      <th>ee_004</th>\n",
       "      <th>ee_005</th>\n",
       "      <th>ee_006</th>\n",
       "      <th>ee_007</th>\n",
       "      <th>ee_008</th>\n",
       "      <th>ee_009</th>\n",
       "      <th>ef_000</th>\n",
       "      <th>eg_000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9042</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9043</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9044</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9045</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9046</th>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9047 rows Ã— 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa_000  ac_000  ad_000  ae_000  af_000  ag_000  ag_001  ag_002  ag_003  \\\n",
       "0          0     0.0     NaN     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1          0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2          0     0.0     NaN     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3          0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4          0     0.0     NaN     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9042       0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9043       0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9044       0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9045       0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9046       0     0.0     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      ag_004  ...  ee_002  ee_003  ee_004  ee_005  ee_006  ee_007  ee_008  \\\n",
       "0        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "1        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "2        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "3        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "4        0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "...      ...  ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "9042     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9043     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9044     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9045     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "9046     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
       "\n",
       "      ee_009  ef_000  eg_000  \n",
       "0        0.0     0.0     0.0  \n",
       "1        0.0     0.0     0.0  \n",
       "2        0.0     0.0     0.0  \n",
       "3        0.0     0.0     0.0  \n",
       "4        0.0     0.0     0.0  \n",
       "...      ...     ...     ...  \n",
       "9042     0.0     0.0     0.0  \n",
       "9043     0.0     0.0     0.0  \n",
       "9044     0.0     0.0     0.0  \n",
       "9045     0.0     0.0     0.0  \n",
       "9046     0.0     0.0     0.0  \n",
       "\n",
       "[9047 rows x 163 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_mice - kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit robust scaler\n",
    "mice_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('RobustScaler',RobustScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit X with Mice imputer\n",
    "X_mice = mice_pipeline.fit_transform(X_mice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa_000       0\n",
      "ac_000    2141\n",
      "ad_000    9200\n",
      "ae_000    1587\n",
      "af_000    1587\n",
      "          ... \n",
      "ee_007     379\n",
      "ee_008     379\n",
      "ee_009     379\n",
      "ef_000    1730\n",
      "eg_000    1729\n",
      "Length: 163, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(X.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = mf.ImputationKernel(X)\n",
    "X = kernel.complete_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smt.fit_resample(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "Resampling successful!\n",
      "Total NaN values in X_mice: 77176\n"
     ]
    }
   ],
   "source": [
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "print(X.isnull().sum().sum())\n",
    "print(np.isinf(X).sum().sum())  # Should print 0\n",
    "print(np.isnan(X).sum().sum())  # Should print 0\n",
    "X = X.astype(float)  # Ensure all values are float\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42)\n",
    "X_resampled, y_resampled = smt.fit_resample(X, y)\n",
    "\n",
    "print(\"Resampling successful!\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Ensure X_mice is a DataFrame\n",
    "if isinstance(X_mice, np.ndarray):\n",
    "    X_mice = pd.DataFrame(X_mice)\n",
    "\n",
    "# Now check for NaN values\n",
    "print(\"Total NaN values in X_mice:\", X_mice.isnull().sum().sum())  # Should be 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTETomek applied successfully!\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")  # Try \"median\" if needed\n",
    "X_mice = imputer.fit_transform(X_mice)  # Keeps X as a NumPy array\n",
    "X_mice = X_mice.astype(float)\n",
    "from imblearn.combine import SMOTETomek\n",
    "\n",
    "smt = SMOTETomek(random_state=42, sampling_strategy='minority', n_jobs=-1)\n",
    "X_res, y_res = smt.fit_resample(X_mice, y)\n",
    "\n",
    "print(\"SMOTETomek applied successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "X = X.dropna()\n",
    "y = y.loc[X.index]\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"mean\")  # Use \"median\" or \"most_frequent\" if needed\n",
    "X = pd.DataFrame(imputer.fit_transform(X), columns=X.columns)\n",
    "\n",
    "print(X.isnull().sum().sum())\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
    "X.fillna(X.mean(), inplace=True)  # Impute again\n",
    "\n",
    "X = X.astype(float)  # Ensure all values are float\n",
    "\n",
    "X.replace([np.inf, -np.inf], np.nan, inplace=True)  # Convert inf to NaN\n",
    "X.fillna(X.mean(), inplace=True)  # Impute again\n",
    "\n",
    "#Resampling the minority class . The strategy can be changed as required\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit the model to generate the data\n",
    "X_res, y_res = smt.fit_resample(X_mice, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9916\n",
      "- F1 score: 0.9917\n",
      "- Precision: 0.9866\n",
      "- Recall: 0.9915\n",
      "-COST: 11960.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9861\n",
      "- F1 score: 0.9863\n",
      "- Precision: 0.9808\n",
      "- Recall: 0.9860\n",
      "-COST: 30370.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9809\n",
      "- F1 score: 0.9812\n",
      "- Precision: 0.9755\n",
      "- Recall: 0.9808\n",
      "-COST: 48250.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9840\n",
      "-F1 score : 0.9840\n",
      "- Precision: 0.9813\n",
      "-Recall: 0.9867\n",
      "- ROC Auc Score : 0.9840\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.6287\n",
      "- F1 score: 0.7162\n",
      "- Precision: 0.5828\n",
      "- Recall: 0.6260\n",
      "-COST: 298030.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.6326\n",
      "-F1 score : 0.7167\n",
      "- Precision: 0.5824\n",
      "-Recall: 0.9317\n",
      "- ROC Auc Score : 0.6332\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9718\n",
      "- F1 score: 0.9724\n",
      "- Precision: 0.9596\n",
      "- Recall: 0.9716\n",
      "-COST: 54430.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9789\n",
      "-F1 score : 0.9791\n",
      "- Precision: 0.9683\n",
      "-Recall: 0.9902\n",
      "- ROC Auc Score : 0.9789\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9949\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9916\n",
      "- Recall: 0.9949\n",
      "-COST: 6100.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9935\n",
      "- F1 score: 0.9936\n",
      "- Precision: 0.9889\n",
      "- Recall: 0.9935\n",
      "-COST: 6790.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9996\n",
      "-F1 score : 0.9996\n",
      "- Precision: 0.9997\n",
      "-Recall: 0.9996\n",
      "- ROC Auc Score : 0.9996\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9695\n",
      "- F1 score: 0.9699\n",
      "- Precision: 0.9645\n",
      "- Recall: 0.9694\n",
      "-COST: 89540.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9696\n",
      "-F1 score : 0.9696\n",
      "- Precision: 0.9656\n",
      "-Recall: 0.9737\n",
      "- ROC Auc Score : 0.9696\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training the models\n",
    "report_mice = evaluate_models(X_res, y_res, models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>5590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>146570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>190760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>377710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1142410</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name      Cost\n",
       "0           Random Forest        0\n",
       "1           Decision Tree        0\n",
       "5           XGBClassifier      500\n",
       "6  CatBoosting Classifier     5590\n",
       "4  K-Neighbors Classifier   146570\n",
       "2       Gradient Boosting   190760\n",
       "7     AdaBoost Classifier   377710\n",
       "3     Logistic Regression  1142410"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline with simple imputer with strategy constant and fill vale 0\n",
    "constant_pipeline = Pipeline(steps=[\n",
    "    ('Imputer', SimpleImputer(strategy='constant,fill_value=0')),\n",
    "    ('RobustScaler',RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(strategy=\"constant\", fill_value=0)  \n",
    "X_const = imputer.fit_transform(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "constant_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy=\"constant\", fill_value=0))  \n",
    "])\n",
    "\n",
    "X_const = constant_pipeline.fit_transform(X)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_const = constant_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling the minority class. The strategy can be changed as required\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit the model to generate the data\n",
    "X_res, y_res=smt.fit_resample(X_const, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9945\n",
      "- F1 score: 0.9946\n",
      "- Precision: 0.9903\n",
      "- Recall: 0.9945\n",
      "-COST: 4690.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9881\n",
      "- F1 score: 0.9883\n",
      "- Precision: 0.9851\n",
      "- Recall: 0.9881\n",
      "-COST: 31560.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9837\n",
      "- F1 score: 0.9839\n",
      "- Precision: 0.9796\n",
      "- Recall: 0.9837\n",
      "-COST: 42960.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9859\n",
      "-F1 score : 0.9859\n",
      "- Precision: 0.9830\n",
      "-Recall: 0.9888\n",
      "- ROC Auc Score : 0.9859\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9416\n",
      "- F1 score: 0.9407\n",
      "- Precision: 0.9631\n",
      "- Recall: 0.9418\n",
      "-COST: 288500.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9448\n",
      "-F1 score : 0.9435\n",
      "- Precision: 0.9631\n",
      "-Recall: 0.9247\n",
      "- ROC Auc Score : 0.9447\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9827\n",
      "- F1 score: 0.9831\n",
      "- Precision: 0.9688\n",
      "- Recall: 0.9826\n",
      "-COST: 9780.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9861\n",
      "-F1 score : 0.9863\n",
      "- Precision: 0.9741\n",
      "-Recall: 0.9988\n",
      "- ROC Auc Score : 0.9862\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9956\n",
      "- F1 score: 0.9956\n",
      "- Precision: 0.9923\n",
      "- Recall: 0.9956\n",
      "-COST: 4050.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9950\n",
      "- F1 score: 0.9950\n",
      "- Precision: 0.9920\n",
      "- Recall: 0.9949\n",
      "-COST: 7570.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9994\n",
      "-F1 score : 0.9994\n",
      "- Precision: 0.9994\n",
      "-Recall: 0.9995\n",
      "- ROC Auc Score : 0.9994\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9680\n",
      "- F1 score: 0.9682\n",
      "- Precision: 0.9688\n",
      "- Recall: 0.9680\n",
      "-COST: 116710.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9678\n",
      "-F1 score : 0.9678\n",
      "- Precision: 0.9675\n",
      "-Recall: 0.9681\n",
      "- ROC Auc Score : 0.9678\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#training the models\n",
    "report_const = evaluate_models(X_res, y_res,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>7660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>23970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>162800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>457140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1067940</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name      Cost\n",
       "0           Random Forest        0\n",
       "1           Decision Tree        0\n",
       "5           XGBClassifier      500\n",
       "6  CatBoosting Classifier     7660\n",
       "4  K-Neighbors Classifier    23970\n",
       "2       Gradient Boosting   162800\n",
       "7     AdaBoost Classifier   457140\n",
       "3     Logistic Regression  1067940"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_const"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a pipeline with Simple imputer with strategy mean\n",
    "mean_pipeline = Pipeline(steps=[\n",
    "    ('Imputer',SimpleImputer(strategy='mean')),\n",
    "    ('RobustScaler',RobustScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_mean = mean_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling the minority class. The strategy can be changed as required\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit the model to generate the data\n",
    "X_res , y_res = smt.fit_resample(X_mean, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9930\n",
      "- F1 score: 0.9930\n",
      "- Precision: 0.9873\n",
      "- Recall: 0.9929\n",
      "-COST: 1230.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9887\n",
      "- F1 score: 0.9888\n",
      "- Precision: 0.9855\n",
      "- Recall: 0.9887\n",
      "-COST: 7260.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9896\n",
      "- F1 score: 0.9897\n",
      "- Precision: 0.9834\n",
      "- Recall: 0.9895\n",
      "-COST: 3800.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9967\n",
      "-F1 score : 0.9967\n",
      "- Precision: 0.9958\n",
      "-Recall: 0.9976\n",
      "- ROC Auc Score : 0.9967\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.7050\n",
      "- F1 score: 0.7650\n",
      "- Precision: 0.6382\n",
      "- Recall: 0.7035\n",
      "-COST: 50160.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.7042\n",
      "-F1 score : 0.7640\n",
      "- Precision: 0.6349\n",
      "-Recall: 0.9589\n",
      "- ROC Auc Score : 0.7046\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9718\n",
      "- F1 score: 0.9723\n",
      "- Precision: 0.9616\n",
      "- Recall: 0.9718\n",
      "-COST: 15700.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9810\n",
      "-F1 score : 0.9811\n",
      "- Precision: 0.9718\n",
      "-Recall: 0.9907\n",
      "- ROC Auc Score : 0.9810\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9961\n",
      "- F1 score: 0.9961\n",
      "- Precision: 0.9933\n",
      "- Recall: 0.9960\n",
      "-COST: 1120.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9938\n",
      "- F1 score: 0.9939\n",
      "- Precision: 0.9889\n",
      "- Recall: 0.9938\n",
      "-COST: 1200.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9825\n",
      "- F1 score: 0.9827\n",
      "- Precision: 0.9768\n",
      "- Recall: 0.9825\n",
      "-COST: 10420.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9864\n",
      "-F1 score : 0.9864\n",
      "- Precision: 0.9847\n",
      "-Recall: 0.9881\n",
      "- ROC Auc Score : 0.9864\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training all models\n",
    "report_mean = evaluate_models(X_res, y_res , models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>8800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>35040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>43090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>184570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name     Cost\n",
       "0           Random Forest       0\n",
       "1           Decision Tree       0\n",
       "5           XGBClassifier       0\n",
       "6  CatBoosting Classifier       0\n",
       "2       Gradient Boosting    8800\n",
       "4  K-Neighbors Classifier   35040\n",
       "7     AdaBoost Classifier   43090\n",
       "3     Logistic Regression  184570"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_pipeline = Pipeline(\n",
    "    steps=[\n",
    "        ('Imputer',SimpleImputer(strategy='constant',fill_value=0)),\n",
    "        ('RobustScaler',RobustScaler())\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pca = pca_pipeline.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applyling pca here to show the machine learning algorithm in generic way\n",
    "from sklearn.decomposition import PCA\n",
    "var_ratio={}\n",
    "for n in range(2,150):\n",
    "    pc = PCA(n_components=n)\n",
    "    df_pca=pc.fit(X_pca)\n",
    "    var_ratio[n]=sum(df_pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 500x500 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Knee Locator K= 18\n"
     ]
    }
   ],
   "source": [
    "from kneed import KneeLocator\n",
    "\n",
    "i = np.arange(len(var_ratio))\n",
    "variance_ratio = list(var_ratio.values())\n",
    "components = list(var_ratio.keys())\n",
    "knee = KneeLocator(i, variance_ratio, curve='concave',direction='increasing', interp_method='polynomial')\n",
    "\n",
    "fig = plt.figure(figsize=(5,5))\n",
    "knee.plot_knee()\n",
    "plt.xlabel(\"Points\")\n",
    "plt.ylabel(\"Distance\")\n",
    "plt.show()\n",
    "k=components[knee.knee] if knee.knee is not None else None\n",
    "print('Knee Locator K=', k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing the dimensions of the data \n",
    "pca_final = PCA(n_components=18,random_state=42).fit(X_res)\n",
    "\n",
    "reduced = pca_final.fit_transform(X_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Resampling the minority class. The strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit the model to generate the data\n",
    "X_res, y_res = smt.fit_resample(reduced,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9839\n",
      "- F1 score: 0.9840\n",
      "- Precision: 0.9783\n",
      "- Recall: 0.9838\n",
      "-COST: 9390.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Decision Tree\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9779\n",
      "- F1 score: 0.9781\n",
      "- Precision: 0.9748\n",
      "- Recall: 0.9779\n",
      "-COST: 16950.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 1.0000\n",
      "-F1 score : 1.0000\n",
      "- Precision: 1.0000\n",
      "-Recall: 1.0000\n",
      "- ROC Auc Score : 1.0000\n",
      "===================================\n",
      "\n",
      "\n",
      "Gradient Boosting\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9652\n",
      "- F1 score: 0.9656\n",
      "- Precision: 0.9599\n",
      "- Recall: 0.9652\n",
      "-COST: 26220.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9703\n",
      "-F1 score : 0.9705\n",
      "- Precision: 0.9656\n",
      "-Recall: 0.9753\n",
      "- ROC Auc Score : 0.9704\n",
      "===================================\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.8871\n",
      "- F1 score: 0.8784\n",
      "- Precision: 0.9568\n",
      "- Recall: 0.8874\n",
      "-COST: 167650.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.8858\n",
      "-F1 score : 0.8767\n",
      "- Precision: 0.9517\n",
      "-Recall: 0.8126\n",
      "- ROC Auc Score : 0.8857\n",
      "===================================\n",
      "\n",
      "\n",
      "K-Neighbors Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9652\n",
      "- F1 score: 0.9656\n",
      "- Precision: 0.9599\n",
      "- Recall: 0.9652\n",
      "-COST: 26220.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9764\n",
      "-F1 score : 0.9766\n",
      "- Precision: 0.9675\n",
      "-Recall: 0.9858\n",
      "- ROC Auc Score : 0.9764\n",
      "===================================\n",
      "\n",
      "\n",
      "XGBClassifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9861\n",
      "- F1 score: 0.9862\n",
      "- Precision: 0.9827\n",
      "- Recall: 0.9861\n",
      "-COST: 9310.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9990\n",
      "-F1 score : 0.9990\n",
      "- Precision: 0.9991\n",
      "-Recall: 0.9989\n",
      "- ROC Auc Score : 0.9990\n",
      "===================================\n",
      "\n",
      "\n",
      "CatBoosting Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9833\n",
      "- F1 score: 0.9835\n",
      "- Precision: 0.9788\n",
      "- Recall: 0.9833\n",
      "-COST: 10880.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9953\n",
      "-F1 score : 0.9953\n",
      "- Precision: 0.9941\n",
      "-Recall: 0.9965\n",
      "- ROC Auc Score : 0.9953\n",
      "===================================\n",
      "\n",
      "\n",
      "AdaBoost Classifier\n",
      "Model performance for Training set\n",
      "- Accuracy: 0.9275\n",
      "- F1 score: 0.9281\n",
      "- Precision: 0.9255\n",
      "- Recall: 0.9275\n",
      "-COST: 62830.\n",
      "--------------------\n",
      "Model performance for Test set\n",
      "-Accuracy: 0.9321\n",
      "-F1 score : 0.9325\n",
      "- Precision: 0.9252\n",
      "-Recall: 0.9399\n",
      "- ROC Auc Score : 0.9321\n",
      "===================================\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training all models \n",
    "report_pca = evaluate_models(X_res,y_res,models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model Name</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>4060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>CatBoosting Classifier</td>\n",
       "      <td>12920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Neighbors Classifier</td>\n",
       "      <td>52340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>89450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost Classifier</td>\n",
       "      <td>217360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>663910</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Model Name     Cost\n",
       "0           Random Forest       0\n",
       "1           Decision Tree       0\n",
       "5           XGBClassifier    4060\n",
       "6  CatBoosting Classifier   12920\n",
       "4  K-Neighbors Classifier   52340\n",
       "2       Gradient Boosting   89450\n",
       "7     AdaBoost Classifier  217360\n",
       "3     Logistic Regression  663910"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------------+------------+\n",
      "|       Model        |    Imputation_method    | Total_cost |\n",
      "+--------------------+-------------------------+------------+\n",
      "|   XGBClassifier    | Simple Imputer-Constant |    2950    |\n",
      "|   XGBClassifier    |           Mice          |    3510    |\n",
      "|   XGBClassifier    |       Knn-Imputer       |    4460    |\n",
      "|   XGBClassifier    |   Simple Imputer-Mean   |    4950    |\n",
      "| CatBoostClassifier |          Median         |    5760    |\n",
      "|   Random Forest    |           PCA           |   34150    |\n",
      "+--------------------+-------------------------+------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "pt = PrettyTable()\n",
    "pt.field_names = [\"Model\",\"Imputation_method\",\"Total_cost\"]\n",
    "pt.add_row([\"XGBClassifier\",\"Simple Imputer-Constant\",\"2950\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Mice\",\"3510\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Knn-Imputer\",\"4460\"])\n",
    "pt.add_row([\"XGBClassifier\",\"Simple Imputer-Mean\",\"4950\"])\n",
    "pt.add_row([\"CatBoostClassifier\",\"Median\",\"5760\"])\n",
    "pt.add_row([\"Random Forest\",\"PCA\",\"34150\"])\n",
    "print(pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = XGBClassifier\n",
    "\n",
    "#Resampling the minority class. The Strategy can be changed as required.\n",
    "smt = SMOTETomek(random_state=42,sampling_strategy='minority',n_jobs=-1)\n",
    "#Fit the model to generate the data\n",
    "X_res, y_res = smt.fit_resample(X_const, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "final_model = XGBClassifier(random_state=42)  # or your custom params\n",
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res,y_res,test_size=0.2,random_state=42)\n",
    "final_model = final_model.fit(X_train, y_train)\n",
    "y_pred = final_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost Classifier Accuracy Score(Train): 1.0\n",
      "Final XGBoost Classifier Accuracy Score (Test): 0.9946704067321178\n"
     ]
    }
   ],
   "source": [
    "print(\"Final XGBoost Classifier Accuracy Score(Train):\",final_model.score(X_train,y_train))\n",
    "print(\"Final XGBoost Classifier Accuracy Score (Test):\",accuracy_score(y_pred,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final XGBoost Classifier Cost Metric(Test) : 1170\n"
     ]
    }
   ],
   "source": [
    "print(\"Final XGBoost Classifier Cost Metric(Test) :\",total_cost(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "cm = confusion_matrix(y_test, final_model.predict(X_test))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
